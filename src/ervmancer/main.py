import argparse
import logging
import os
import sys
import datetime
import subprocess
import pkg_resources
from tqdm import tqdm
from .preprocessing.filter_reads import ReadFilter


def run_command(cmd):
    try:
        subprocess.run(cmd, shell=True, check=True)
    except subprocess.CalledProcessError as e:
        logging.error(f"Command failed: {cmd}")
        raise e


def get_timestamp():
    """Generate a timestamp string for file naming."""
    return datetime.datetime.now().strftime("%Y%m%d_%H%M")


def get_data_path(filename):
    """Get the path to a data file included in the package."""
    try:
        # Installed package - ERVmancer
        return pkg_resources.resource_filename('ervmancer', os.path.join('data', filename))
    except (ImportError, ModuleNotFoundError):
        # Developer Mode
        return os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'data', filename)


def main():
    parser = argparse.ArgumentParser(description='ervmancer')
    parser.add_argument('--b', type=str, required=False,
                        help="User provided absolute path to self provided bowtie2 alignment file")
    parser.add_argument('--r1', required=False,
                        help='Absolute path to paired-end R1 fastq file.')
    parser.add_argument('--r2', required=False,
                        help='Absolute path to paired-end R2 fastq file.')
    parser.add_argument('--s1', required=False,
                        help='Absolute path to single strand S1 fastq file.')
    parser.add_argument('--keep_files', action='store_true', default=False,
                        help="Keeps intermediate outputs from Samtools and Bedtools.")
    parser.add_argument('--num_cores', type=int, default=8,
                        help="Number of CPU cores used for processing.")
    parser.add_argument('--output_dir', required=True,
                        help='Absolute path to base output directory for CSV output and intermediate files. (Output folders are autogenerated if they do not exist already!)')
    parser.add_argument('--bowtie_index', required=True,
                        help="Absolute path to the Bowtie2 index to be used for processing.")

    args = parser.parse_args()

    logging.basicConfig(level=logging.INFO,
                        format='%(asctime)s - %(levelname)s - %(message)s', force=True)

    try:
        # Create output directories
        for subdir in ['intermediate_files', 'final', 'logs']:
            os.makedirs(os.path.join(args.output_dir, subdir), exist_ok=True)

        read_filter = ReadFilter(args.output_dir, args.r1, args.r2, args.s1)
        base_name, paired = read_filter.validate_inputs()
        logging.info(f'Base Name: {base_name}')

        os.makedirs(os.path.join(args.output_dir,
                    "intermediate_files"), exist_ok=True)
        timestamp = get_timestamp()

        if args.b:
            try:
                # Convert to absolute path
                outsam_pathname = os.path.abspath(args.b)
                # Check if the path exists
                if os.path.exists(outsam_pathname):
                    # Parse given path as an absolute path for consumption
                    logging.info(
                        f"Using user provided alignment file: {outsam_pathname}")
                else:
                    logging.info(
                        "Path to provided alignment file is invalid. File does not exist. Terminating program.")
                    sys.exit(1)
            except Exception as e:
                logging.error(f"Error processing path: {str(e)}")
                sys.exit(1)
        else:
            outsam_pathname = read_filter.get_path(
                'intermediate_files', f'{base_name}_{timestamp}_bowtie2_out', 'sam')
        outbam_pathname = read_filter.get_path(
            'intermediate_files', f'{base_name}_{timestamp}_all_hervs', 'bam')
        sorted_outbam_pathname = read_filter.get_path(
            'intermediate_files', f'{base_name}_{timestamp}_sorted', 'bam')
        converted_herv_gtf_to_bed = get_data_path('hervs_genomic_coords.bed')
        logging.info(f"Using HERV BED file: {converted_herv_gtf_to_bed}")
        outbed_pathname = read_filter.get_path(
            'final', f'{base_name}_{timestamp}_multimap_', 'bed')
        # Bedtools intersect with HERV GTF file (Multimap)
        subset_outsam_pathname = read_filter.get_path(
            'intermediate_files', f'{base_name}_{timestamp}_hervs_subset', 'sam')
        # Filter unique read appearances (step for KMER)
        subset_outbam_pathname = read_filter.get_path(
            'final', f'{base_name}_{timestamp}_all_hervs.bwa_read', 'bam')

        commands = [
            f"samtools view -bS {outsam_pathname} -o {outbam_pathname}",
            f"samtools sort -@ {args.num_cores} {outbam_pathname} -o {sorted_outbam_pathname}",
            f"samtools index {sorted_outbam_pathname}",
            # Multimap uses this intermediate output below in the final dir
            f"bedtools intersect -abam {sorted_outbam_pathname} -b {converted_herv_gtf_to_bed} -wa -wb -bed > {outbed_pathname}",
            # Kmer step uses this intermediate output in the final dir
            f"bedtools intersect -abam {sorted_outbam_pathname} -b {converted_herv_gtf_to_bed} > {subset_outsam_pathname}",
            f"samtools view -h -o {subset_outsam_pathname} {subset_outbam_pathname}"
        ]
        if not args.b:
            # if bowtie file is not provided by user, add the bowtie 2 commands with unified mode parameters
            if paired:
                logging.info("Bowtie 2 - Unified Mode, paired reads")
                bt_cmd = f"""bowtie2 -p {args.num_cores} --very-sensitive --end-to-end -X 1500 \
                --no-mixed --no-discordant --no-dovetail --no-unal --score-min L,-0.1,-0.1 \
                -x {args.bowtie_index} -1 {read_filter.r1_path} -2 {read_filter.r2_path} -k 100 -S {outsam_pathname} \
                2> {read_filter.get_path('logs', base_name, 'bt2_paired_strict.err')}"""
            else:
                logging.info("Bowtie 2 - Unified Mode, single strand")
                bt_cmd = f"""bowtie2 -p {args.num_cores} -N 1 -L 10 --very-sensitive --end-to-end --no-unal \
                -x {args.bowtie_index} --score-min L,-0.1,-0.1 -U {read_filter.s1_path} -k 100 -S {outsam_pathname} \
                2> {read_filter.get_path('logs', base_name, 'bt2_single_strict.err')}"""
            # insert the bowtie 2 command to the front of the pipeline commands queue
            commands.insert(0, bt_cmd)

        logging.info("Starting processing pipeline...")
        for cmd in tqdm(commands, desc="Processing commands"):
            logging.info(f"Executing: {cmd}")
            run_command(cmd)

        cleanup_dir = os.path.join(args.output_dir, 'intermediate_files')
        if not args.keep_files:
            logging.info("Cleaning up intermediate files...")
            if os.path.exists(cleanup_dir):
                for filename in os.listdir(cleanup_dir):
                    file_path = os.path.join(cleanup_dir, filename)
                    try:
                        if os.path.isfile(file_path):
                            os.remove(file_path)
                            logging.debug(
                                f"Removed intermediate file: {file_path}")
                    except Exception as e:
                        logging.error(f"Error removing {file_path}: {e}")
                logging.info(f"Cleanup of {cleanup_dir} complete")
            else:
                logging.warning(
                    f"Cleanup directory {cleanup_dir} does not exist or is not a directory")
        logging.info("Processing complete!")

    except Exception as e:
        logging.error(f"An error occurred: {str(e)}")
        raise


if __name__ == "__main__":
    main()
